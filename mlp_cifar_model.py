# -*- coding: utf-8 -*-
"""MLP-CIFAR model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lLyGdicPN6S3Da7cXXRAahQI6G1sG62U

```
MLP model for computer vision
```
Task:
Train and evaluate mulitilayer perceptron model on the CIFAR 10 dataset to recognize clothing items.

I'm working on a similar model I used on MNIST fashion dataset

Importing dependencies and defining visualizing methods first!
"""

import tensorflow

from tensorflow.keras import datasets, layers, models

import matplotlib.pyplot as plt
from IPython.display import Image

def show_images(images: list) -> None:
    n: len(images)
    f = plt.figure()
    for i in range(n):
        f.add_subplot(1, n, i + 1)
        plt.imshow(images[i], cmap='gray')
    plt.show(block=True)

def show_image(image) -> None:
    plt.imshow(image, cmap='gray')
    plt.show(block=True)

def show_online_image(target_url):
    # Image(url= "https://gluon.mxnet.io/_images/dcgan.png")
    Image(url= target_url)

def plot_images_labels_prediction(images,labels,prediction,idx,num=10):
    fig=plt.gcf()
    fig.set_size_inches(12, 14)
    if num > 25: num=25
    for i in range(0, num):
        ax=plt.subplot(5, 5, i+1)
        ax.imshow(images[idx], cmap='binary')
        title="label=" + str(labels[idx])
        if len(prediction) > 0:
            title += ",predict=" + str(prediction[idx])
        ax.set_title(title, fontsize=10)
        ax.set_xticks([]);
        ax.set_yticks([]);
        idx += 1
    plt.show()

def show_train_history(train_history):
    fig=plt.gcf()
    fig.set_size_inches(16, 6)
    plt.subplot(121)
    print(train_history.history.keys())

    if "accuracy" in train_history.history.keys():
        plt.plot(train_history.history["accuracy"])

    if "val_accuracy" in train_history.history.keys():
        plt.plot(train_history.history["val_accuracy"])

    plt.title("Train History")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend(["train", "validation"], loc="upper left")
    plt.subplot(122)

    if "loss" in train_history.history.keys():
        plt.plot(train_history.history["loss"])

    if "val_loss" in train_history.history.keys():
        plt.plot(train_history.history["val_loss"])

    plt.title("Train History")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(["train", "validation"], loc="upper left")
    plt.show()

"""Loading the CIFAR 10 dataset and visualizing the data"""

(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train[i])
    # The CIFAR labels happen to be arrays,
    # which is why you need the extra index
    plt.xlabel(class_names[y_train[i][0]])
plt.show()

"""Make image into a vector so it can be used as MLP input

"""

sample = x_train[0]

# origin image
show_image(sample)

# input of MLP, a images were transfer into a vector
# show_image(sample.reshape(1, 28 * 28))

#print  to observe shape
print(x_train.shape)
num_samples = x_train.shape[0]
num_features = x_train.shape[1] * x_train.shape[2] * x_train.shape[3]

# x_train = x_train.reshape(num_samples, num_features)

# update all the training, testing dataset.

x_train = x_train.reshape(50000, 32*32*3)
x_test = x_test.reshape(10000, 32*32*3)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')


# reshape the input data to match the expected

#print again to observe shape
# x_train = x_train.reshape(-1, 28, 28)
print(x_train.shape)

"""Preparing the model"""

import keras
from tensorflow.keras import layers
import numpy as np

num_classes = 10

# create a Sequential model
model = keras.Sequential(

    [
         # Flatten layer to reshape the 32x32x3 images to a 3072 vector - before passing to other layers
        layers.Flatten(input_shape=(3072,)),

        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.2),

        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.2),

        layers.Dense(num_classes, activation='softmax')
        ]
);

"""```
Total params: 269322 (1.03 MB)
Trainable params: 269322 (1.03 MB)
Non-trainable params: 0 (0.00 Byte)
```

Compiling the model using model.compile()

Here are the parameters:
```
Optimizer : how to optimize your weights.
Loss : loss function.
Metrics : how to evaluate your model.
Batch : there are 2 ways to update your weights in model
  update everytime after watching an input.
  update once after watching batch of inputs.
here we update once for 1000 inputs.
Epochs : how many times you want to look overwhole your datas.

```
"""

# x_train = x_train.reshape(-1, 28, 28, 1)
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

batch_size = 256
epochs = 10
history = model.fit(x_train, y_train,
                    epochs=epochs,
                    validation_split=0.2)

"""Looking at the results of the model: evaluate it's efficiency on test data"""

scores, acc = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', scores)
print('Test accuracy:', acc)

"""*Results*:

```
Test loss: 1.556602120399475
Test accuracy: 0.4478999972343445
```

Visualizing the prediction accuracy
"""

#show train history
show_train_history(history)

"""Generate a confusion matrix:"""

from sklearn.metrics import confusion_matrix
import numpy as np

# Make predictions on the test data
y_pred = model.predict(x_test)

# Convert the predicted probabilities to class labels
y_pred_classes = np.argmax(y_pred, axis=1)

# Generate the confusion matrix
confusion_matrix = confusion_matrix(y_test, y_pred_classes)

# Print the confusion matrix
print(confusion_matrix)

"""Save the model:

"""

model_name = 'cifar_mlp.h5'
model.save(model_name, save_format='h5')